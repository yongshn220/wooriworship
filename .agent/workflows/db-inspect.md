---
description: database 구조, 연동성 및 데이터 무결성을 심층 분석하고 개선점을 도출합니다.
---

이 워크플로우는 데이터베이스 구조와 데이터 간의 연동 로직을 분석하여 성능, 격리성, 무결성 관점의 개선안을 도출하는 프로세스입니다.

### 1단계: 기존 구조 및 문서 분석
- `db-data-schema.md`와 `db-evaluation.md` 문서를 먼저 읽어 전체적인 아키텍처와 알려진 한계점을 파악합니다.
- `models/` 디렉토리의 파일들을 전수 조사하여 각 엔티티의 최신 필드 구성과 데이터 타입을 확인합니다.

### 2단계: 데이터 연동 및 상호 의존성 분석
- `apis/` 디렉토리의 서비스 파일들을 스캔하여 다음 패턴을 찾습니다:
  - **비원자적 업데이트**: 한 번의 사용자 동작으로 여러 문서가 업데이트될 때 트랜잭션(`runTransaction`)을 사용하지 않는 구간.
  - **중첩된 데이터**: 배열 내부에 검색이 필요한 데이터가 들어가 있어 쿼리 성능이 저하되는 구간 (예: `participants` 등의 인덱스 필드 필요 여부).
  - **종속성 삭제**: 한 문서를 지울 때 연관된 다른 문서(악보, 댓글, 초대 등)가 올바르게 정리되는지 여부.

### 3단계: 일관성 및 공유 로직 검사
- **날짜 정규화**: `Timestamp`, `Date`, `string`이 혼용되고 있는지 보고, 날짜 정규화(예: 낮 12:00)가 일관되게 적용되는지 확인합니다.
- **데이터 공유(Sharing)**: 예배와 봉사표처럼 날짜/태그로 묶이는 데이터들의 연결 방식(`correlation_key` 등)이 효율적인지 분석합니다.
- **파생 상테(Derived State)**: 태그 통계(`tag_stats`)나 곡 사용 이력(`last_used_time`) 등 다른 데이터를 기반으로 업데이트되는 정보의 동기화 방식을 점검합니다.

### 4단계: 개선 제안 및 계획 수립
- 분석 결과를 바탕으로 다음을 포함한 `implementation_plan.md`를 업데이트합니다:
  - 서브 컬렉션화를 통한 데이터 격리 전략.
  - 트랜잭션 적용을 통한 무결성 확보 방안.
  - 검색 성능 향상을 위한 역정규화(Flattened Index) 제안.

### 5단계: 검증 계획
- 마이그레이션 도중 데이터 유실을 방지하기 위한 체크섬(Checksum) 또는 샘플 검증 계획을 수립합니다.
